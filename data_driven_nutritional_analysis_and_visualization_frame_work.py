# -*- coding: utf-8 -*-
"""Data -Driven Nutritional analysis and Visualization frame work

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MWShv8rqb5Qo_NF8NW2yM8mYj7CQmcb7
"""

from google.colab import files
uploaded = files.upload()

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('nutrients_data (1).csv')

# View the first five rows of the dataset
df.head()

# View the information about dataset
df.info()

df.duplicated().sum()

df.head(3)

sns.set_style('darkgrid')

# Clean 'Calories' and 'Fat' columns
# Explicitly convert to string type before applying string methods to handle potential re-executions
df['Calories'] = pd.to_numeric(df['Calories'].astype(str).str.replace(',', '', regex=False), errors='coerce')
df['Fat'] = pd.to_numeric(df['Fat'].astype(str).replace('t', np.nan), errors='coerce')

# Create a figure with 1 row and 2 columns
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Distribution of Calories
sns.histplot(df['Calories'], kde=True, ax=axes[0], color='blue')
axes[0].set_title('Distribution of Calories')

# Distribution of Fat
sns.histplot(df['Fat'], kde=True, ax=axes[1], color='orange')
axes[1].set_title('Distribution of Fat')

# Adjust layout and show the plot
plt.tight_layout()
plt.show()

# Clean 'Protein' and 'Carbs' columns, converting to numeric
df['Protein'] = pd.to_numeric(df['Protein'].astype(str).replace('t', np.nan).str.replace(',', '', regex=False), errors='coerce')
df['Carbs'] = pd.to_numeric(df['Carbs'].astype(str).replace('t', np.nan).str.replace(',', '', regex=False), errors='coerce')

# Compute correlations with correct column names
selected_columns = ['Calories', 'Fat', 'Carbs', 'Protein']
corr = df[selected_columns].corr()

g = sns.pairplot(df[selected_columns])

# Add correlation coefficients
for i, j in zip(*np.triu_indices_from(corr, k=1)):
    ax = g.axes[i, j]
    ax.annotate(f"r={corr.iloc[i, j]:.2f}", (0.5, 0.9), xycoords='axes fraction', ha='center')
plt.show()

# Clean 'Grams', 'Sat.Fat', and 'Fiber' columns, converting to numeric
df['Grams'] = pd.to_numeric(df['Grams'].astype(str).str.replace(',', '', regex=False).replace('t', np.nan), errors='coerce')
df['Sat.Fat'] = pd.to_numeric(df['Sat.Fat'].astype(str).str.replace(',', '', regex=False).replace('t', np.nan), errors='coerce')
df['Fiber'] = pd.to_numeric(df['Fiber'].astype(str).str.replace(',', '', regex=False).replace('t', np.nan), errors='coerce')

food_groups = df.groupby('Food').mean(numeric_only=True).reset_index()

# Calculate 'Nutrition Density'
# To avoid division by zero or NaNs where Calories might be 0 or NaN, we can replace them with a small number or handle them specifically.
# For simplicity, let's fill NaN Calories with 1 to avoid division by zero, assuming 0 calorie items are rare or handled by other means.
food_groups['Nutrition Density'] = (food_groups['Protein'] + food_groups['Fiber']) / food_groups['Calories'].replace(0, np.nan)
# Fill any resulting NaNs (e.g., from division by zero or missing protein/fiber) with 0 for sorting purposes
food_groups['Nutrition Density'] = food_groups['Nutrition Density'].fillna(0)

top_nutrition_density_foods = food_groups.sort_values(by='Nutrition Density', ascending=False).head(10)
plt.figure(figsize=(12, 8))
sns.barplot(x='Nutrition Density', y='Food', data=top_nutrition_density_foods, palette='viridis')
plt.title('Top 10 Food Items by Nutrition Density')
plt.show()

X = df.drop(columns=['Fat'],axis=1)
y = df['Fat']

num_cols = X.select_dtypes(include=np.number).columns.to_list()
cat_cols = X.select_dtypes(exclude=np.number).columns.to_list()

print(num_cols, end='\n\n')
print(cat_cols)

num_pipeline = Pipeline(steps=[
    ('scaler', MinMaxScaler())
])

cat_pipeline = Pipeline(steps=[
    ('one_hot_enc', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

col_trans = ColumnTransformer(transformers=[
    ('num_pipeline', num_pipeline, num_cols),
    ('cat_pipeline', cat_pipeline, cat_cols),
    ],
    remainder='drop',
    n_jobs=-1
)

X_processed = col_trans.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=12)

# Initialize models
linear_model = LinearRegression()
randon_forest_model = RandomForestRegressor(random_state=42)

# Handle NaNs in y_train and y_test by creating a mask for non-NaN values
# This ensures X and y remain aligned
import pandas as pd
import numpy as np

not_nan_train_mask = ~pd.Series(y_train).isnull()
not_nan_test_mask = ~pd.Series(y_test).isnull()

X_train_filtered = X_train[not_nan_train_mask]
y_train_filtered = y_train[not_nan_train_mask]

X_test_filtered = X_test[not_nan_test_mask]
y_test_filtered = y_test[not_nan_test_mask]

# Impute NaNs in the filtered X_train and X_test
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='mean') # Using mean strategy for imputation

# Fit imputer on X_train_filtered and transform both training and testing features
X_train_imputed = imputer.fit_transform(X_train_filtered)
X_test_imputed = imputer.transform(X_test_filtered)

# Train Linear Regression with imputed and filtered data
linear_model.fit(X_train_imputed, y_train_filtered)
y_pred_linear = linear_model.predict(X_test_imputed)

# Train Random Forest Regressor with imputed and filtered data
randon_forest_model.fit(X_train_imputed, y_train_filtered)
y_pred_rf = randon_forest_model.predict(X_test_imputed)

def evaluate_model(y_test, y_pred, model_name):
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print(f"{model_name}:\n RMSE: {rmse:.2f}, MAE: {mae:.2f}, R²: {r2:.2f}\n")
    return rmse, mae, r2

metrics_linear = evaluate_model(y_test_filtered, y_pred_linear, "Linear Regression")
metrics_rf = evaluate_model(y_test_filtered, y_pred_rf, "Random Forest Regressor")

labels = ['Linear Regression', 'Random Forest']
rmse_values = [metrics_linear[0], metrics_rf[0]]
mae_values = [metrics_linear[1], metrics_rf[1]]

x = np.arange(len(labels))
width = 0.35  # Bar width

# Plot RMSE and MAE
fig, ax = plt.subplots(figsize=(8, 6))
bar1 = ax.bar(x - width/2, rmse_values, width, label='RMSE', color='dodgerblue')
bar2 = ax.bar(x + width/2, mae_values, width, label='MAE', color='orange')

# Add counts at the top of each bar
for bar in bar1:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2.0, height + 0.1,
            f'{height:.2f}', ha='center', va='bottom', fontsize=10)

for bar in bar2:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2.0, height + 0.1,
            f'{height:.2f}', ha='center', va='bottom', fontsize=10)

# Add labels, title, and legend
ax.set_xlabel('Model')
ax.set_ylabel('Error Value')
ax.set_title('RMSE and MAE Comparison')
ax.set_xticks(x)
ax.set_xticklabels(labels)
ax.legend()

plt.tight_layout()
plt.show()

r2_values = [metrics_linear[2], metrics_rf[2]]

plt.figure(figsize=(8, 6))
bar3 = plt.bar(labels, r2_values, color=['seagreen', 'limegreen'])

# Add counts at the top of each bar
for bar in bar3:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2.0, height + 0.005,
             f'{height:.2f}', ha='center', va='bottom', fontsize=10)

# Add labels and title
plt.title('R² Score Comparison')
plt.ylabel('R² Score')
plt.xlabel('Model')
plt.tight_layout()
plt.show()

!git init

!git add README.md

!git commit -m "first commit"

!git branch -M main

!git remote add origin https://github.com/mettajeevanbalaji/project.git

!git push -u origin main

# Create a sample README.md file
!echo "# My Project" > README.md
!echo "This is my Colab project." >> README.md

# Add the README.md file to staging
!git add README.md

# Commit the changes (ensure your git config --global user.email and user.name are set!)
!git commit -m "Add README.md"

!git config --global user.email "your_email@example.com"
!git config --global user.name "Your Name"

# Now try pushing again after committing
!git push -u origin main

!git config --global user.email "mettajeevanbalaji31@example.com"
!git config --global user.name "metta jeevan balaji"

